import os
import re
import random
import pandas as pd
from pydub import AudioSegment
from audiomentations import Compose, AddGaussianNoise, TimeStretch, PitchShift
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import classification_report, confusion_matrix
import xgboost as xgb
import whisper
import nltk
import joblib

nltk.download('punkt')

BASE_DIR = os.path.abspath(os.path.join(os.path.dirname(__file__), ".."))

# === –ù–∞—Å—Ç—Ä–æ–π–∫–∏ ===
INPUT_DIR = os.path.join(BASE_DIR, "conversations")
OUTPUT_DIR = os.path.join(BASE_DIR, "app/models")
AUGMENTED_DIR = os.path.join(BASE_DIR, "conversations_augmented")

print(f"–ö–æ—Ä–Ω–µ–≤–∞—è –ø–∞–ø–∫–∞ –ø—Ä–æ–µ–∫—Ç–∞: {BASE_DIR}")
print(f"–ü—É—Ç—å –∫ –¥–∞–Ω–Ω—ã–º: {INPUT_DIR}")
print(f"–ü—É—Ç—å –∫ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º: {OUTPUT_DIR}")
print(f"–ü—É—Ç—å –∫ –∞—É–≥–º–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–º –¥–∞–Ω–Ω—ã–º: {AUGMENTED_DIR}")

keywords = {"–ø–æ–∫—É–ø–∫–∞", "–∑–∞–∫–∞–∑", "–¥–æ—Å—Ç–∞–≤–∫–∞", "–æ–ø–ª–∞—Ç–∞", "—É—Å–ª—É–≥–∞"}
neutral_phrases = ["—É–≥—É", "—è—Å–Ω–æ", "–ø–æ–Ω—è—Ç–Ω–æ", "—Å–ø–∞—Å–∏–±–æ", "–∞–≥–∞", "—Ö–æ—Ä–æ—à–æ", "–ª–∞–¥–Ω–æ", "—Ç–∞–∫"]

# === Whisper Model (base) ===
print("üîÑ –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ Whisper (base)...")
model = whisper.load_model("base")
print("‚úÖ –ú–æ–¥–µ–ª—å Whisper (base) –∑–∞–≥—Ä—É–∂–µ–Ω–∞!")

def recognize(mp3_path):
    try:
        result = model.transcribe(mp3_path, language="ru")
        text = result["text"]
        print(f"üó£ –†–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç: {text}")
        return text
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è {mp3_path}: {e}")
        return ""

def extract_features(text):
    text = text.lower()
    words = nltk.word_tokenize(text)
    duration_est = len(words)
    kw_count = sum(1 for w in words if w in keywords)
    return {
        "duration_sec": duration_est,
        "keywords_count": kw_count,
    }

# === –û–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö ===
records = []

label_map = {
    "hot": "–ì–æ—Ä—è—á–∏–π",
    "warm": "–¢—ë–ø–ª—ã–π",
    "cold": "–•–æ–ª–æ–¥–Ω—ã–π"
}

for label_folder, label_name in label_map.items():
    folder_path = os.path.join(INPUT_DIR, label_folder)
    if not os.path.isdir(folder_path):
        continue

    for filename in os.listdir(folder_path):
        if filename.endswith(".mp3"):
            path = os.path.join(folder_path, filename)
            print(f"üîç –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ñ–∞–π–ª: {filename}")

            original_text = recognize(path)
            if original_text:
                feats = extract_features(original_text)
                feats["interest_level"] = label_name
                records.append(feats)

print(f"–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–ø–∏—Å–µ–π: {len(records)}")
if len(records) == 0:
    print("‚ö†Ô∏è –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è!")
    exit(1)

# === –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ ===
df = pd.DataFrame(records)
X = df.drop("interest_level", axis=1)
label_encoder = LabelEncoder()
y_encoded = label_encoder.fit_transform(df["interest_level"])

X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)
model = xgb.XGBClassifier(objective="multi:softmax", num_class=3, eval_metric="mlogloss", use_label_encoder=False)
model.fit(X_train, y_train)

# === –û—Ü–µ–Ω–∫–∞ ===
y_pred = model.predict(X_test)
print("\nConfusion matrix:\n", confusion_matrix(y_test, y_pred))
print("\nClassification report:\n", classification_report(y_test, y_pred, target_names=label_encoder.classes_))

# === –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ ===
os.makedirs(OUTPUT_DIR, exist_ok=True)
joblib.dump(model, os.path.join(OUTPUT_DIR, "xgboost_call_model.pkl"))
joblib.dump(label_encoder, os.path.join(OUTPUT_DIR, "label_encoder.pkl"))
print("\n‚úÖ –û–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ –∏ –º–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞.")

